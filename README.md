# Previs√£o da temperatura de <i>melting</i> de prote√≠nas com um dom√≠nio por meio de redes neurais

<h2 align="left">Introdu√ß√£o</h2>
<blockquote> 
<p align="justify">Sauda√ß√µes!¬†Sejam bem-vindos ao nosso projeto. :smiley_cat:</p>
<p align="justify">Nosso grupo √© formado por <a href="https://github.com/gustavercosa">Gustavo Duarte Ver√ßosa</a>, <a href="https://github.com/jpab2004">Jo√£o Pedro Aroucha de Brito</a>, <a href="https://github.com/selaxco">Thaynara Beatriz Selasco de Matos</a> e <a href="https://github.com/viyuetuki">Vit√≥ria Yumi Uetuki Nicoleti</a>. Somos alunos de Ci√™ncia e Tecnologia, curso este que est√° sendo feito na <a href="https://ilum.cnpem.br/">Ilum Escola de Ci√™ncia</a>, faculdade do <a href="https://cnpem.br/">Centro Nacional de Pesquisa em Energia e Materiais (CNPEM)</a>.</p>
<p align="justify">Este projeto surgiu como nossa apresenta√ß√£o final para a disciplina de <b>Redes Neurais e Algoritmos Gen√©ticos</b>, ministrada pelo professor doutor <a href="https://github.com/drcassar">Daniel Roberto Cassar</a>. Com a tem√°tica de incorporar conceitos biol√≥gicos, decidimos explorar uma caracter√≠stica f√≠sico-qu√≠mica das prote√≠nas: <b>a temperatura de <i>melting</i></b>. Motivados por essa perspectiva, optamos por utilizar redes neurais para realizar a previs√£o da temperatura de <i>melting</i> de prote√≠nas com um dom√≠nio.</p> 
<img src="https://img.shields.io/badge/STATUS-Em%20desenvolvimento-576CFB"> <img src="https://img.shields.io/badge/LICENCE-GNU%20General%20Public%20License%20v3.0-75CA75">
</blockquote> 

<h3 align="left">O que √© temperatura de <i>melting</i>? :fire:</h3>
<blockquote> 
<p align="justify"> </p>
</blockquote>

<h3 align="left">Por que usar redes neurais? üë©üèª‚Äçüíª</h3>
<blockquote> 
<p align="justify"> </p>
</blockquote>

<h2 align="left">Banco de dados</h2>
<blockquote> 
<p align="justify"> </p>
</blockquote> 

<h2 align="left">Metodologia</h2>
<blockquote> 
<p align="justify"> </p>
</blockquote> 

<h3 align="left">Compara√ß√µes :eyes:</h3>
<blockquote> 
<p align="justify">As fun√ß√µes de ativa√ß√£o desempenham um papel essencial nas redes neurais, sendo respons√°veis por influenciar a sa√≠da de um neur√¥nio. 
Neste contexto, foram testadas tr√™s fun√ß√µes de ativa√ß√£o: a <a href="https://paperswithcode.com/method/sigmoid-activation">Sigmoid Activation</a>, a <a href="https://paperswithcode.com/method/leaky-relu">Leaky ReLU</a> e a <a href="https://paperswithcode.com/method/swish">Swish</a>.</p>
  <blockquote> 
  <p align="justify">A fun√ß√£o de ativa√ß√£o sigm√≥ide √© uma fun√ß√£o n√£o linear que mapeia valores de entrada para um intervalo entre 0 e 1. √â amplamente utilizada em problemas de classifica√ß√£o bin√°ria, onde a sa√≠da √© 0 ou 1. A fun√ß√£o sigm√≥ide possui um gradiente suave, o que facilita a otimiza√ß√£o usando o gradiente descendente. No entanto, ela tamb√©m apresenta algumas desvantagens, como o problema do gradiente que desaparece, o que pode tornar o treinamento de redes neurais profundas mais desafiador.</p>
  <p align="justify">A fun√ß√£o de ativa√ß√£o Leaky ReLU √© uma variante da fun√ß√£o ReLU que aborda o problema conhecido como "morte ReLU". Ela introduz uma pequena inclina√ß√£o para valores negativos, permitindo que o neur√¥nio tenha uma sa√≠da diferente de zero mesmo quando a entrada √© negativa. Essa inclina√ß√£o geralmente √© definida como um valor pequeno, como 0.01. Embora o Leaky ReLU seja computacionalmente mais exigente em compara√ß√£o com o ReLU, ele pode ajudar a evitar o problema do gradiente que desaparece, que √© comum em redes neurais profundas.</p>
  <p align="justify">A fun√ß√£o de ativa√ß√£o Swish √© uma fun√ß√£o relativamente nova que ganhou popularidade nos √∫ltimos anos. Ela √© suave e n√£o monot√¥nica, semelhante √† fun√ß√£o sigmoide. O Swish √© definido como a multiplica√ß√£o da entrada pelo resultado da fun√ß√£o sigmoide aplicada √† entrada. Essa fun√ß√£o inclui um par√¢metro $\beta$ que pode ser aprendido. O Swish demonstrou superar o ReLU e outras fun√ß√µes de ativa√ß√£o em alguns casos, mas √© computacionalmente mais exigente em compara√ß√£o com o ReLU.</p>
  </blockquote>
<p align="justify">Em geral, a sele√ß√£o da fun√ß√£o de ativa√ß√£o depende do problema espec√≠fico e da arquitetura da rede neural.</p>
</blockquote>

<h2 align="left">Conclus√£o</h2>
<blockquote> 
<p align="justify">A conclus√£o do nosso projeto ser√° apresentada durante uma aula no dia 22 de junho de 2023, no per√≠odo da tarde. Ap√≥s uma semana dessa apresenta√ß√£o, esta se√ß√£o ser√° reestruturada e atualizada aqui.</p>
</blockquote> 

<h2 align="left">Agradecimentos</h2>
<blockquote> 
<p align="justify">Gostar√≠amos de expressar nossos sinceros agradecimentos, em especial ao professor doutor Daniel Roberto Cassar, por sua valiosa contribui√ß√£o ao explorar a disciplina conosco e discutir a elabora√ß√£o do projeto.</p>
<p align="justify">Al√©m disso, gostar√≠amos de agradecer √† professora doutora Juliana Helena Costa Smetana por seu interesse e aux√≠lio no entendimento dos aspectos biol√≥gicos do projeto. Sua participa√ß√£o foi fundamental para o desenvolvimento do nosso trabalho.</p>
</blockquote> 
  
<h2 align="left">Refer√™ncias</h2>
<blockquote> 
<p align="justify">[1] </p>
<p align="justify">[2] TALAPATI, Sumalatha Rani; GOYAL, Megha; NATARAJ, Vijayashankar; <i>et al</i>. Structural and binding studies of cyclin‚Äêdependent kinase 2 with NU6140 inhibitor. <b>Chemical Biology & Drug Design</b>, v.¬†98, n.¬†5, p.¬†857‚Äì868, 2021.
</p>
<p align="justify">[3] CHELTSOV, Anton; NOMURA, Natsuko; YENUGONDA, Venkata; <i>et al</i>. Allosteric inhibitor of Œ≤-catenin selectively targets oncogenic Wnt signaling in colon cancer. <b>Scientific Reports</b>, v.¬†10, n.¬†1, p.¬†8096, 2020.</p>
</blockquote> 
