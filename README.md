# Previs√£o da temperatura de <i>melting</i> de prote√≠nas com um dom√≠nio por meio de redes neurais

<h2 align="left">Introdu√ß√£o</h2>
<blockquote> 
<p align="justify">Sauda√ß√µes!¬†Sejam bem-vindos ao nosso projeto. :smiley_cat:</p>
<p align="justify">Nosso grupo √© formado por <a href="https://github.com/gustavercosa">Gustavo Duarte Ver√ßosa</a>, <a href="https://github.com/jpab2004">Jo√£o Pedro Aroucha de Brito</a>, <a href="https://github.com/selaxco">Thaynara Beatriz Selasco de Matos</a> e <a href="https://github.com/viyuetuki">Vit√≥ria Yumi Uetuki Nicoleti</a>. Somos alunos de Ci√™ncia e Tecnologia, curso este que est√° sendo feito na <a href="https://ilum.cnpem.br/">Ilum Escola de Ci√™ncia</a>, faculdade do <a href="https://cnpem.br/">Centro Nacional de Pesquisa em Energia e Materiais (CNPEM)</a>.</p>
<p align="justify">Este projeto surgiu como nossa apresenta√ß√£o final para a disciplina de <b>Redes Neurais e Algoritmos Gen√©ticos</b>, ministrada pelo professor doutor <a href="https://github.com/drcassar">Daniel Roberto Cassar</a>. Com a tem√°tica de incorporar conceitos biol√≥gicos, decidimos explorar uma caracter√≠stica f√≠sico-qu√≠mica das prote√≠nas: <b>a temperatura de <i>melting</i></b>. Motivados por essa perspectiva, optamos por utilizar redes neurais para realizar a previs√£o da temperatura de <i>melting</i> de prote√≠nas com um dom√≠nio.</p> 
<img src="https://img.shields.io/badge/STATUS-Em%20desenvolvimento-576CFB"> <img src="https://img.shields.io/badge/LICENCE-GNU%20General%20Public%20License%20v3.0-75CA75">
</blockquote> 

<h3 align="left">O que √© temperatura de <i>melting</i>? :fire:</h3>
<blockquote> 
<p align="justify"> </p>
</blockquote>

<h3 align="left">Por que usar redes neurais? üë©üèª‚Äçüíª</h3>
<blockquote> 
<p align="justify"> Antes de entender a raz√£o de escolhermos utilizar redes neurais, √© importante entender o que elas s√£o e como elas funcionam. Baseado no c√©rebro humano, esse modelo de intelig√™ncia artificial √© capaz de reconhecer padr√µes existentes em um conjunto de dados e aprender com os erros cometidos. Mas de onde surgiu a analogia com o c√©rebro? Bom, no sentido em que estamos trabalhando, falar dos neur√¥nios diz respeito, principalmente, a conectividade que eles s√£o capazes de fazer uns com os outros e a import√¢ncia dela para as tomadas de decis√µes com base nos padr√µes identificados. </p>
<p align="justify">A arquitetura das redes neurais consiste, basicamente, em uma camada que recebe os dados de entrada, uma ou mais camadas ocultas respons√°veis por realizar opera√ß√µes em uma fun√ß√£o de ativa√ß√£o que determina como a sa√≠da √© calculada e, enfim, uma camada de sa√≠da. Cada um dos neur√¥nios possui um peso atribu√≠do a ele, que √© modificado conforme a rede precisa ser ajustada de modo a minimizar o erro entre a sa√≠da produzida e a sa√≠da desejada.</p>

</blockquote>

<h2 align="left">Banco de dados</h2>
<blockquote> 
<p align="justify"> </p>
</blockquote> 

<h2 align="left">Metodologia</h2>
<blockquote> 
<p align="justify"> Como explicado anteriormente, o projeto visa utilizar Redes Neurais como um poss√≠vel m√©todo de determina√ß√£o da temperatura de melting de porte√≠nas de um √∫nico dominio, por√©m, precisamo primeiramente entender como essas redes neurais foram construidas e quais as poss√≠veis altera√ß√µes que podem ser feitas nos modelos. As redes neurais desenvolvidas no projeto possuem uma estrutura similar entre si e podem ser consideradas como muito parecidas, justamente por conta de um dos objetivos ser a compara√ß√£o de diferentes implementa√ß√µes e os resultados obtidos com tais.</p>
<p align="justify">A primeira etapa para estrutra√ß√£o da rede foi pensar nas camadas escondidas (hidden layers) que ir√£o compor as redes. Chegou-se na conclus√£o que poderiam ser utilizadas redes com 3 camadas escondidades que poderiam ter seus tamanhos vari√°veis a fim de compara√ß√£o da efic√°cia e diferencia√ß√£o destas.</p>
<p align="justify">Come√ßou-se ent√£o a etapa de an√°lise das features a serem fornecidas para a rede. Os dados obtidos atrav√©s do banco de dados exposto anteriormente explicitam a presen√ßa de algumas possibilidades para esses dados de entrada (input) para as redes, por√©m, foi feita uma determina√ß√£o destes dados, sendo consideradas as facilidades de obten√ß√£o de tais dados em conjunto com a disponibilidade de acesso de tais informa√ß√µes. Com esta an√°lise, chegamos a idealiza√ß√£o de 21 ou 22 dados de entrada que seriam alimentados a rede em busca da temperatura de melting da prote√≠na originadora dos dados.</p>
<p align="justify">Os primeiros 20 dados a serem considerados s√£o de facil acesso, principalmente em plataformas como o banco de dados online de prote√≠nas <a href='https://www.uniprot.org'>UniProt</a> e se trata da quantiza√ß√£o dos amino√°cidos presentes na cadeia da prote√≠na, ou seja, a rede receberia a quantidade de vezes que cada amino√°cido se encontra na prote√≠na. A escolha desta informa√ß√£o foi feita pela simplicidade e escalabilidade da rede para prote√≠nas de diferentes tamanho sem que seja alterada sua estrutura b√°sica.</p>
<p align="justify">Os outros dados a serem considerados s√£o, na verdade, apenas um dado, mas expresso de 2 diferentes formas. Uma das informa√ß√µes obtidas no banco de dados √© justamente os aditivos presentes em solu√ß√£o com as prote√≠nas estudadas, levando a uma altera√ß√£o nas temperaturas de melting de tais prote√≠nas pela intera√ß√£o destas com os aditivos. Pensou-se ent√£o em uma forma de passar estes dados n√£o num√©ricos as redes que precisam de dados num√©ricos. Com a an√°lise cuidadosa, foi poss√≠vel a obten√ß√£o de dois m√©todos de trasnforma√ß√£o dos dados em n√∫meros. O primeiro m√©todo consiste na determina√ß√£o de um peso para cada uma das possibilidades de aditivos que seriam ent√£o somados e dividios pelo total dos pesos, gerando um valor de ponto flutuante entre 0 e 1. Um exemplo desta aplica√ß√£o pode ser visto abaixo, onde o aditivo 1 possui um peso de 1 e o aditivo 2 possui um peso de 2.</p>

<center>

| Aditivo 1 | Aditivo 2 | Total (soma / soma dos pesos) |
| :------------: | :------------: | :------------: |
| 0 | 0 | 0 |
| 1 | 0 | 0.33333 |
| 0 | 1 | 0.66666 |
| 1 | 1 | 1 |
  
</center>

<p align="justify"> O segundo m√©todo de transforma√ß√£o dos dados seria uma simples separa√ß√£o dos dados em dois valores bin√°rios, o primeiro valor num√©rico representaria a presen√ßa ou n√£o do aditivo 1, enquanto o segundo representaria a presen√ßa ou n√£o do aditivo 2. Os dois m√©todos foram utilizados para a cria√ß√£o das redes, desta forma, √© poss√≠vel a constru√ß√£o de redes que podem ser alteradas de diferentes formas para compara√ß√£o de efic√°cia. </p>

<p align="justify">Ao todo foram utilizadas 6 poss√≠veis combina√ß√µes diferentes de m√©todos, sendo estas combina√ß√µes atingidas pela utiliza√ß√£o de 2 formas diferentes de input para o dados de aditivos e outras 3 fun√ß√µes de ativa√ß√£o que foram escolhidas para serem aplicadas ao problema.</p>
<p align="justify">Vamos ver um pouco sobre cada um dessas diferen√ßas aplicadas. </p>
</blockquote> 

<h3 align="left">Compara√ß√µes :eyes:</h3>

<blockquote> 
<p align="justify">As fun√ß√µes de ativa√ß√£o desempenham um papel essencial nas redes neurais, sendo respons√°veis por influenciar a sa√≠da de um neur√¥nio. 
Neste contexto, foram testadas tr√™s fun√ß√µes de ativa√ß√£o: a <a href="https://paperswithcode.com/method/sigmoid-activation">Sigmoid Activation</a>, a <a href="https://paperswithcode.com/method/leaky-relu">Leaky ReLU</a> e a <a href="https://paperswithcode.com/method/swish">Swish</a>.</p>
  <blockquote> 
  <p align="justify">A fun√ß√£o de ativa√ß√£o sigm√≥ide √© uma fun√ß√£o n√£o linear que mapeia valores de entrada para um intervalo entre 0 e 1. √â amplamente utilizada em problemas de classifica√ß√£o bin√°ria, onde a sa√≠da √© 0 ou 1. A fun√ß√£o sigm√≥ide possui um gradiente suave, o que facilita a otimiza√ß√£o usando o gradiente descendente. No entanto, ela tamb√©m apresenta algumas desvantagens, como o problema do gradiente que desaparece, o que pode tornar o treinamento de redes neurais profundas mais desafiador.</p>
  <p align="justify">A fun√ß√£o de ativa√ß√£o Leaky ReLU √© uma variante da fun√ß√£o ReLU que aborda o problema conhecido como "morte ReLU". Ela introduz uma pequena inclina√ß√£o para valores negativos, permitindo que o neur√¥nio tenha uma sa√≠da diferente de zero mesmo quando a entrada √© negativa. Essa inclina√ß√£o geralmente √© definida como um valor pequeno, como 0.01. Embora o Leaky ReLU seja computacionalmente mais exigente em compara√ß√£o com o ReLU, ele pode ajudar a evitar o problema do gradiente que desaparece, que √© comum em redes neurais profundas.</p>
  <p align="justify">A fun√ß√£o de ativa√ß√£o Swish √© uma fun√ß√£o relativamente nova que ganhou popularidade nos √∫ltimos anos. Ela √© suave e n√£o monot√¥nica, semelhante √† fun√ß√£o sigmoide. O Swish √© definido como a multiplica√ß√£o da entrada pelo resultado da fun√ß√£o sigmoide aplicada √† entrada. Essa fun√ß√£o inclui um par√¢metro $\beta$ que pode ser aprendido. O Swish demonstrou superar o ReLU e outras fun√ß√µes de ativa√ß√£o em alguns casos, mas √© computacionalmente mais exigente em compara√ß√£o com o ReLU.</p>
  </blockquote>
<p align="justify">Em geral, a sele√ß√£o da fun√ß√£o de ativa√ß√£o depende do problema espec√≠fico e da arquitetura da rede neural.</p>
<p align="justify">Ap√≥s a conclus√£o de todos os treinos e testes programas, foram calculados os erros m√©dios para cada uma das seis situa√ß√µes determinadas.</p>
<center>

| Leaky ReLU com _float_ | Leaky ReLU com bin√°rio | Sigmoid com _float_ | Sigmoid com bin√°rio | Swish com _float_ | Swish com bin√°rio |
| :--------------------: | :--------------------: | :-----------------: | :-----------------: | :---------------: | :---------------: |
| 3.650 ¬∞C | 3.810 ¬∞C | 4.420 ¬∞C | 4.600 ¬∞C | 4.117 ¬∞C | 4.440 ¬∞C |

</center>
<p align="justify">Com base nesse resultado, foi constatado que a fun√ß√£o de ativa√ß√£o Leaky ReLU com o tipo de dado <i>float</i> apresentou o menor erro m√©dio, sendo selecionada como o m√©todo decisivo. Em seguida, foi conduzido um √∫ltimo teste, no qual foi obtido o valor de 3.992 ¬∞C.</p>
<p align="justify">Por √∫ltimo, procedemos com o teste utilizando valores externos ao banco de dados. Foram escolhidas duas prote√≠nas: a quinase dependente de ciclina do <i>Homo sapiens</i> e a beta-catenina do peixe-zebra (<i>Danio rerio</i>). √â importante ressaltar que a beta-catenina, al√©m de n√£o pertencer √† esp√©cie humana, possui mais de 300 amino√°cidos, o que a diferencia consideravelmente dos valores presentes no banco de dados.</p>
<p align="justify">Para a quinase dependente de ciclina:</p>
<center>

| _Output_ da rede | Valor de refer√™ncia | Erro aproximado | 
| :--------------: | :-----------------: | :-------------: |
| 51.493 ¬∞C | 45 ¬∞C | 7 ¬∞C |

</center>
<p align="justify">Para a beta-catenina:</p>
<center>

| _Output_ da rede | Valor de refer√™ncia | Erro aproximado | 
| :--------------: | :-----------------: | :-------------: |
| 58.180 ¬∞C | 52 ¬∞C | 6 ¬∞C |

</center>
</blockquote>

<h2 align="left">Conclus√£o</h2>
<blockquote> 
<p align="justify">Com base nos resultados obtidos, pudemos observar uma tend√™ncia clara ao analisar apenas a estrutura prim√°ria das prote√≠nas. Os valores de temperatura de _melting_ para a nossa sele√ß√£o de prote√≠nas variaram entre 67 ¬∞C (valor m√°ximo) e 40.83 ¬∞C (valor m√≠nimo), e constatamos que o erro foi pequeno, representando apenas um quarto da diferen√ßa entre os pontos extremos. √â importante ressaltar que a temperatura de _melting_ pode ser facilmente influenciada por fatores externos, como aditivos na solu√ß√£o e pH.</p>
<p align="justify">Nesse sentido, os pr√≥ximos passos ser√£o:</p>
  <ol>
  <li><p align="justify">Aprimorar ainda mais o treinamento da rede neural;</p></li>
  <li><p align="justify">Estudar prote√≠nas com mais de um dom√≠nio;</p></li>
  <li><p align="justify">Incorporar informa√ß√µes estruturais, como a estrutura terci√°ria e quatern√°ria.</p></li>
</ol>
<p align="justify">Com esses dados, focados na co-evolu√ß√£o, poderemos investigar mais profundamente como determinar essa informa√ß√£o utilizando apenas par√¢metros bioqu√≠micos.</p>
</blockquote>

<h2 align="left">Agradecimentos</h2>
<blockquote> 
<p align="justify">Gostar√≠amos de expressar nossos sinceros agradecimentos, em especial ao professor doutor Daniel Roberto Cassar, por sua valiosa contribui√ß√£o ao explorar a disciplina conosco e discutir a elabora√ß√£o do projeto.</p>
<p align="justify">Al√©m disso, gostar√≠amos de agradecer √† professora doutora Juliana Helena Costa Smetana por seu interesse e aux√≠lio no entendimento dos aspectos biol√≥gicos do projeto. Sua participa√ß√£o foi fundamental para o desenvolvimento do nosso trabalho.</p>
</blockquote> 
  
<h2 align="left">Refer√™ncias</h2>
<blockquote> 
<p align="justify">[1] REINHARD, Friedrich B M; EBERHARD, Dirk; WERNER, Thilo; <i>et al</i>. Thermal proteome profiling monitors ligand interactions with cellular membrane proteins. <b>Nature Methods</b>, v.¬†12, n.¬†12, p.¬†1129‚Äì1131, 2015.
</p>
<p align="justify">[2] TALAPATI, Sumalatha Rani; GOYAL, Megha; NATARAJ, Vijayashankar; <i>et al</i>. Structural and binding studies of cyclin‚Äêdependent kinase 2 with NU6140 inhibitor. <b>Chemical Biology & Drug Design</b>, v.¬†98, n.¬†5, p.¬†857‚Äì868, 2021.
</p>
<p align="justify">[3] CHELTSOV, Anton; NOMURA, Natsuko; YENUGONDA, Venkata; <i>et al</i>. Allosteric inhibitor of Œ≤-catenin selectively targets oncogenic Wnt signaling in colon cancer. <b>Scientific Reports</b>, v.¬†10, n.¬†1, p.¬†8096, 2020.</p>
</blockquote>
